# Fiche d'ActivitÃ© Pratique : K Plus Proches Voisins (KNN) avec Scikit-Learn
## Objectif
Comprendre et mettre en Å“uvre l'algorithme des **K Plus Proches Voisins (KNN)** Ã  l'aide de la bibliothÃ¨que Scikit-Learn en Python.
## PrÃ©requis  
* Python installÃ© sur la machine
* Les bibliothÃ¨ques Scikit-Learn, NumPy et Matplotlib.
## Introduction
L'algorithme des **K Plus Proches Voisins (KNN)** est une mÃ©thode d'apprentissage supervisÃ© utilisÃ©e pour la classification et la rÃ©gression. Il se base sur le principe que des points similaires se trouvent gÃ©nÃ©ralement dans des zones proches les unes des autres. KNN attribue une classe Ã  un point de donnÃ©es en fonction des classes majoritaires parmi ses k voisins les plus proches.
**I. Qu'est-ce que les K Plus Proches Voisins (KNN) ?**
L'idÃ©e fondamentale de KNN est de trouver les k voisins les plus proches d'un point de donnÃ©es donnÃ© et de prendre une dÃ©cision en fonction des classes majoritaires parmi ces voisins. La distance entre les points peut Ãªtre mesurÃ©e de diffÃ©rentes maniÃ¨res, souvent par la distance euclidienne.

L'algorithme KNN peut Ãªtre utilisÃ© pour la classification et la rÃ©gression :
- **Classification :** La classe majoritaire parmi les k voisins est attribuÃ©e au point de donnÃ©es.
- **RÃ©gression :** La valeur moyenne ou mÃ©diane des k voisins est attribuÃ©e au point de donnÃ©es.
  
**II. Mise en Pratique avec Scikit-Learn :**  
**Installation de Scikit-Learn :**
  Assurez-vous d'avoir Scikit-Learn installÃ©. Sinon, installez-le via la commande : 
```sh
pip install scikit-learn
```
**Importation des BibliothÃ¨ques :**
```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
```
**GÃ©nÃ©ration de DonnÃ©es :**
```python
np.random.seed(42)
X = 2 * np.random.rand(100, 2)
y = (X[:, 0] + X[:, 1] > 1).astype(int)
```
**EntraÃ®nement du ModÃ¨le :**
```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

k_value = 3
model = KNeighborsClassifier(n_neighbors=k_value)
model.fit(X_train, y_train)
```
**PrÃ©diction et Ã‰valuation :**
```python
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Confusion Matrix:\n{confusion_mat}")
```
## Conclusion
Les **K Plus Proches Voisins** sont une mÃ©thode simple mais efficace pour la classification et la rÃ©gression. Scikit-Learn offre des outils puissants pour mettre en Å“uvre cet algorithme en Python. En pratiquant cette activitÃ©, vous avez maintenant les bases pour explorer davantage les concepts de KNN et son application dans le domaine de l'apprentissage automatique.
## License
```sh
                                                     __  __       _        _          _______             
                                                    |  \/  |     | |      (_)        |__   __|            
                                                    | \  / | __ _| |_ _ __ ___  __      | | ___ _ __ __ _ 
                                                    | |\/| |/ _` | __| '__| \ \/ /      | |/ _ \ '__/ _` |
                                                    | |  | | (_| | |_| |  | |>  <       | |  __/ | | (_| |
                                                    |_|  |_|\__,_|\__|_|  |_/_/\_\      |_|\___|_|  \__,_|   ðŸ‡²ðŸ‡¬
```
                                                       




